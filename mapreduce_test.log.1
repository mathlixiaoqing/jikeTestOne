DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@7e2d773b
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@1a3869f4
 DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
 DEBUG main org.apache.hadoop.ipc.Client - Connecting to localhost/127.0.0.1:12345
 INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:12345. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:12345. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@4c203ea1
 INFO main org.apache.hadoop.ipc.CallQueueManager - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.ipc.Server - Server accepts auth methods:[SIMPLE]
 DEBUG IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà: starting, having connections 1
 DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà sending #0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Starting Socket Reader #1 for port 12345
 DEBUG main org.apache.hadoop.ipc.metrics.RpcMetrics - Initialized MetricsRegistry{info=MetricsInfoImpl{name=rpc, description=rpc}, tags=[MetricsTag{info=MetricsInfoImpl{name=port, description=RPC port}, value=12345}], metrics=[]}
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.receivedBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of received bytes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.sentBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of sent bytes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.rpcQueueTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Queue time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.rpcProcessingTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Processing time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.deferredRpcProcessingTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Deferred Processing time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthenticationFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authentication failures], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthenticationSuccesses with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authentication successes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthorizationFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authorization failures], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthorizationSuccesses with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authorization successes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcClientBackoff with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of client backoff requests], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcSlowCalls with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of Slow RPC calls], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public int org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnections() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of open connections], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public java.lang.String org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnectionsPerUser() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of open connections per user], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public long org.apache.hadoop.ipc.metrics.RpcMetrics.numDroppedConnections() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of dropped connections], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public int org.apache.hadoop.ipc.metrics.RpcMetrics.callQueueLength() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Length of the call queue], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - RpcActivityForPort12345, Aggregate RPC metrics
 DEBUG main org.apache.hadoop.ipc.metrics.RpcDetailedMetrics - MetricsInfoImpl{name=rpcdetailed, description=rpcdetailed}
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.rates with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.deferredRpcRates with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - RpcDetailedActivityForPort12345, Per method RPC metrics
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.ipc.Server - RpcKind = RPC_PROTOCOL_BUFFER Protocol Name = org.apache.hadoop.ipc.ProtocolMetaInfoPB version=1 ProtocolImpl=org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolInfoService$2 protocolClass=org.apache.hadoop.ipc.ProtocolMetaInfoPB
 DEBUG main org.apache.hadoop.ipc.Server - RpcKind = RPC_WRITABLE Protocol Name = jike.HadoopRPC.MyInterface version=1 ProtocolImpl=jike.HadoopRPC.Impl.MyInterfaceImpl protocolClass=jike.HadoopRPC.MyInterface
 INFO IPC Server Responder org.apache.hadoop.ipc.Server - IPC Server Responder: starting
 INFO IPC Server listener on 12345 org.apache.hadoop.ipc.Server - IPC Server listener on 12345: starting
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: starting
 DEBUG IPC Server listener on 12345 org.apache.hadoop.ipc.Server - Server connection from 127.0.0.1:57129; # active connections: 1; # queued calls: 0
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #-3
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Successfully authorized userInfo {
  effectiveUser: "\303\224\303\250\321\251\303\207\303\240"
}
protocol: "jike.HadoopRPC.MyInterface"

 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #0
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57129 for RpcKind RPC_WRITABLE
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:ÔèѩÇà (auth:SIMPLE) from:org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - add
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - findName
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - add
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - findName
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - Served: findName queueTime= 4 procesingTime= 6
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57129
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57129 Wrote 130 bytes.
 DEBUG IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà got value #0
 DEBUG main org.apache.hadoop.ipc.RPC - Call: findName 8386
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: readAndProcess from client 127.0.0.1:57129 threw exception [java.io.IOException: 远程主机强迫关闭了一个现有的连接。]
 java.io.IOException: 远程主机强迫关闭了一个现有的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.ipc.Server.channelRead(Server.java:3262)
	at org.apache.hadoop.ipc.Server.access$2600(Server.java:137)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2037)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1242)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1098)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1069)
DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: disconnecting client 127.0.0.1:57129. Number of active connections: 0
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@4d50efb8
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@77ec78b9
 DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
 DEBUG main org.apache.hadoop.ipc.Client - Connecting to localhost/127.0.0.1:12345
 INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:12345. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:12345. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:12345. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:12345. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:12345. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@4c203ea1
 INFO main org.apache.hadoop.ipc.CallQueueManager - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.ipc.Server - Server accepts auth methods:[SIMPLE]
 INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:12345. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Starting Socket Reader #1 for port 12345
 DEBUG main org.apache.hadoop.ipc.metrics.RpcMetrics - Initialized MetricsRegistry{info=MetricsInfoImpl{name=rpc, description=rpc}, tags=[MetricsTag{info=MetricsInfoImpl{name=port, description=RPC port}, value=12345}], metrics=[]}
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.receivedBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of received bytes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.sentBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of sent bytes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.rpcQueueTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Queue time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.rpcProcessingTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Processing time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.deferredRpcProcessingTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Deferred Processing time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthenticationFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authentication failures], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthenticationSuccesses with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authentication successes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthorizationFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authorization failures], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthorizationSuccesses with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authorization successes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcClientBackoff with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of client backoff requests], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcSlowCalls with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of Slow RPC calls], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public int org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnections() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of open connections], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public java.lang.String org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnectionsPerUser() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of open connections per user], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public long org.apache.hadoop.ipc.metrics.RpcMetrics.numDroppedConnections() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of dropped connections], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public int org.apache.hadoop.ipc.metrics.RpcMetrics.callQueueLength() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Length of the call queue], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - RpcActivityForPort12345, Aggregate RPC metrics
 DEBUG main org.apache.hadoop.ipc.metrics.RpcDetailedMetrics - MetricsInfoImpl{name=rpcdetailed, description=rpcdetailed}
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.rates with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.deferredRpcRates with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - RpcDetailedActivityForPort12345, Per method RPC metrics
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.ipc.Server - RpcKind = RPC_PROTOCOL_BUFFER Protocol Name = org.apache.hadoop.ipc.ProtocolMetaInfoPB version=1 ProtocolImpl=org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolInfoService$2 protocolClass=org.apache.hadoop.ipc.ProtocolMetaInfoPB
 DEBUG main org.apache.hadoop.ipc.Server - RpcKind = RPC_WRITABLE Protocol Name = jike.HadoopRPC.MyInterface version=1 ProtocolImpl=jike.HadoopRPC.Impl.MyInterfaceImpl protocolClass=jike.HadoopRPC.MyInterface
 INFO IPC Server Responder org.apache.hadoop.ipc.Server - IPC Server Responder: starting
 INFO IPC Server listener on 12345 org.apache.hadoop.ipc.Server - IPC Server listener on 12345: starting
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: starting
 DEBUG IPC Server listener on 12345 org.apache.hadoop.ipc.Server - Server connection from 127.0.0.1:57444; # active connections: 1; # queued calls: 0
 DEBUG IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà: starting, having connections 1
 DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà sending #0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #-3
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Successfully authorized userInfo {
  effectiveUser: "\303\224\303\250\321\251\303\207\303\240"
}
protocol: "jike.HadoopRPC.MyInterface"

 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #0
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57444 for RpcKind RPC_WRITABLE
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:ÔèѩÇà (auth:SIMPLE) from:org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - add
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - findName
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - add
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - findName
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - Served: findName queueTime= 4 procesingTime= 4
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57444
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57444 Wrote 130 bytes.
 DEBUG IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà got value #0
 DEBUG main org.apache.hadoop.ipc.RPC - Call: findName 18706
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: readAndProcess from client 127.0.0.1:57444 threw exception [java.io.IOException: 远程主机强迫关闭了一个现有的连接。]
 java.io.IOException: 远程主机强迫关闭了一个现有的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.ipc.Server.channelRead(Server.java:3262)
	at org.apache.hadoop.ipc.Server.access$2600(Server.java:137)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2037)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1242)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1098)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1069)
DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: disconnecting client 127.0.0.1:57444. Number of active connections: 0
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@7e2d773b
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@1a3869f4
 DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
 DEBUG main org.apache.hadoop.ipc.Client - Connecting to localhost/127.0.0.1:12345
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@4c203ea1
 INFO main org.apache.hadoop.ipc.CallQueueManager - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.ipc.Server - Server accepts auth methods:[SIMPLE]
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Starting Socket Reader #1 for port 12345
 DEBUG main org.apache.hadoop.ipc.metrics.RpcMetrics - Initialized MetricsRegistry{info=MetricsInfoImpl{name=rpc, description=rpc}, tags=[MetricsTag{info=MetricsInfoImpl{name=port, description=RPC port}, value=12345}], metrics=[]}
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.receivedBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of received bytes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.sentBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of sent bytes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.rpcQueueTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Queue time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.rpcProcessingTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Processing time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.deferredRpcProcessingTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Deferred Processing time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthenticationFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authentication failures], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthenticationSuccesses with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authentication successes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthorizationFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authorization failures], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthorizationSuccesses with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authorization successes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcClientBackoff with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of client backoff requests], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcSlowCalls with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of Slow RPC calls], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public long org.apache.hadoop.ipc.metrics.RpcMetrics.numDroppedConnections() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of dropped connections], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public int org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnections() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of open connections], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public java.lang.String org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnectionsPerUser() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of open connections per user], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public int org.apache.hadoop.ipc.metrics.RpcMetrics.callQueueLength() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Length of the call queue], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - RpcActivityForPort12345, Aggregate RPC metrics
 DEBUG main org.apache.hadoop.ipc.metrics.RpcDetailedMetrics - MetricsInfoImpl{name=rpcdetailed, description=rpcdetailed}
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.rates with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.deferredRpcRates with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - RpcDetailedActivityForPort12345, Per method RPC metrics
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.ipc.Server - RpcKind = RPC_PROTOCOL_BUFFER Protocol Name = org.apache.hadoop.ipc.ProtocolMetaInfoPB version=1 ProtocolImpl=org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolInfoService$2 protocolClass=org.apache.hadoop.ipc.ProtocolMetaInfoPB
 DEBUG main org.apache.hadoop.ipc.Server - RpcKind = RPC_WRITABLE Protocol Name = jike.HadoopRPC.MyInterface version=1 ProtocolImpl=jike.HadoopRPC.Impl.MyInterfaceImpl protocolClass=jike.HadoopRPC.MyInterface
 INFO IPC Server Responder org.apache.hadoop.ipc.Server - IPC Server Responder: starting
 INFO IPC Server listener on 12345 org.apache.hadoop.ipc.Server - IPC Server listener on 12345: starting
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: starting
 INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:12345. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 DEBUG IPC Server listener on 12345 org.apache.hadoop.ipc.Server - Server connection from 127.0.0.1:57478; # active connections: 1; # queued calls: 0
 DEBUG IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà: starting, having connections 1
 DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà sending #0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #-3
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Successfully authorized userInfo {
  effectiveUser: "\303\224\303\250\321\251\303\207\303\240"
}
protocol: "jike.HadoopRPC.MyInterface"

 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #0
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57478 for RpcKind RPC_WRITABLE
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:ÔèѩÇà (auth:SIMPLE) from:org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - add
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - findName
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - add
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - findName
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - Served: findName queueTime= 4 procesingTime= 5
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57478
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57478 Wrote 57 bytes.
 DEBUG IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà got value #0
 DEBUG main org.apache.hadoop.ipc.RPC - Call: findName 3171
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: readAndProcess from client 127.0.0.1:57478 threw exception [java.io.IOException: 远程主机强迫关闭了一个现有的连接。]
 java.io.IOException: 远程主机强迫关闭了一个现有的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.ipc.Server.channelRead(Server.java:3262)
	at org.apache.hadoop.ipc.Server.access$2600(Server.java:137)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2037)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1242)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1098)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1069)
DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: disconnecting client 127.0.0.1:57478. Number of active connections: 0
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@4d50efb8
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@77ec78b9
 DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
 DEBUG main org.apache.hadoop.ipc.Client - Connecting to localhost/127.0.0.1:12345
 DEBUG IPC Server listener on 12345 org.apache.hadoop.ipc.Server - Server connection from 127.0.0.1:57487; # active connections: 1; # queued calls: 0
 DEBUG IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà: starting, having connections 1
 DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà sending #0 findName(20210735010150), rpc version=2, client version=1, methodsFingerPrint=1436578371
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #-3
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Successfully authorized userInfo {
  effectiveUser: "\303\224\303\250\321\251\303\207\303\240"
}
protocol: "jike.HadoopRPC.MyInterface"

 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #0
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: Call#0 Retry#0 findName(20210735010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57487 for RpcKind RPC_WRITABLE
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:ÔèѩÇà (auth:SIMPLE) from:org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - Served: findName queueTime= 0 procesingTime= 1
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210735010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57487
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210735010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57487 Wrote 60 bytes.
 DEBUG IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà got value #0
 DEBUG main org.apache.hadoop.ipc.RPC - Call: findName 114
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: readAndProcess from client 127.0.0.1:57487 threw exception [java.io.IOException: 远程主机强迫关闭了一个现有的连接。]
 java.io.IOException: 远程主机强迫关闭了一个现有的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.ipc.Server.channelRead(Server.java:3262)
	at org.apache.hadoop.ipc.Server.access$2600(Server.java:137)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2037)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1242)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1098)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1069)
DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: disconnecting client 127.0.0.1:57487. Number of active connections: 0
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@4d50efb8
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@77ec78b9
 DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
 DEBUG main org.apache.hadoop.ipc.Client - Connecting to localhost/127.0.0.1:12345
 INFO main org.apache.hadoop.ipc.Client - Retrying connect to server: localhost/127.0.0.1:12345. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@4c203ea1
 INFO main org.apache.hadoop.ipc.CallQueueManager - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.ipc.Server - Server accepts auth methods:[SIMPLE]
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Starting Socket Reader #1 for port 12345
 DEBUG main org.apache.hadoop.ipc.metrics.RpcMetrics - Initialized MetricsRegistry{info=MetricsInfoImpl{name=rpc, description=rpc}, tags=[MetricsTag{info=MetricsInfoImpl{name=port, description=RPC port}, value=12345}], metrics=[]}
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.receivedBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of received bytes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.sentBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of sent bytes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.rpcQueueTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Queue time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.rpcProcessingTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Processing time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.deferredRpcProcessingTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Deferred Processing time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthenticationFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authentication failures], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthenticationSuccesses with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authentication successes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthorizationFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authorization failures], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthorizationSuccesses with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of authorization successes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcClientBackoff with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of client backoff requests], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcSlowCalls with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of Slow RPC calls], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public int org.apache.hadoop.ipc.metrics.RpcMetrics.callQueueLength() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Length of the call queue], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public java.lang.String org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnectionsPerUser() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of open connections per user], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public long org.apache.hadoop.ipc.metrics.RpcMetrics.numDroppedConnections() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of dropped connections], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public int org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnections() with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Number of open connections], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - RpcActivityForPort12345, Aggregate RPC metrics
 DEBUG main org.apache.hadoop.ipc.metrics.RpcDetailedMetrics - MetricsInfoImpl{name=rpcdetailed, description=rpcdetailed}
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.rates with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.deferredRpcRates with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - RpcDetailedActivityForPort12345, Per method RPC metrics
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà: starting, having connections 1
 DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà sending #0 findName(20235010150), rpc version=2, client version=1, methodsFingerPrint=1436578371
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.ipc.Server - RpcKind = RPC_PROTOCOL_BUFFER Protocol Name = org.apache.hadoop.ipc.ProtocolMetaInfoPB version=1 ProtocolImpl=org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolInfoService$2 protocolClass=org.apache.hadoop.ipc.ProtocolMetaInfoPB
 DEBUG main org.apache.hadoop.ipc.Server - RpcKind = RPC_WRITABLE Protocol Name = jike.HadoopRPC.MyInterface version=1 ProtocolImpl=jike.HadoopRPC.Impl.MyInterfaceImpl protocolClass=jike.HadoopRPC.MyInterface
 INFO IPC Server Responder org.apache.hadoop.ipc.Server - IPC Server Responder: starting
 INFO IPC Server listener on 12345 org.apache.hadoop.ipc.Server - IPC Server listener on 12345: starting
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: starting
 DEBUG IPC Server listener on 12345 org.apache.hadoop.ipc.Server - Server connection from 127.0.0.1:57508; # active connections: 1; # queued calls: 0
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #-3
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Successfully authorized userInfo {
  effectiveUser: "\303\224\303\250\321\251\303\207\303\240"
}
protocol: "jike.HadoopRPC.MyInterface"

 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #0
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: Call#0 Retry#0 findName(20235010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57508 for RpcKind RPC_WRITABLE
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:ÔèѩÇà (auth:SIMPLE) from:org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - add
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - findName
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - add
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - findName
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - Served: findName queueTime= 4 procesingTime= 9
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20235010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57508
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20235010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57508 Wrote 130 bytes.
 DEBUG IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà got value #0
 DEBUG main org.apache.hadoop.ipc.RPC - Call: findName 4261
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: readAndProcess from client 127.0.0.1:57508 threw exception [java.io.IOException: 远程主机强迫关闭了一个现有的连接。]
 java.io.IOException: 远程主机强迫关闭了一个现有的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.ipc.Server.channelRead(Server.java:3262)
	at org.apache.hadoop.ipc.Server.access$2600(Server.java:137)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2037)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1242)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1098)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1069)
DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: disconnecting client 127.0.0.1:57508. Number of active connections: 0
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@7e2d773b
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@1a3869f4
 DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
 DEBUG main org.apache.hadoop.ipc.Client - Connecting to localhost/127.0.0.1:12345
 DEBUG IPC Server listener on 12345 org.apache.hadoop.ipc.Server - Server connection from 127.0.0.1:57528; # active connections: 1; # queued calls: 0
 DEBUG IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà: starting, having connections 1
 DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà sending #0 findName(20235010150), rpc version=2, client version=1, methodsFingerPrint=1436578371
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #-3
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Successfully authorized userInfo {
  effectiveUser: "\303\224\303\250\321\251\303\207\303\240"
}
protocol: "jike.HadoopRPC.MyInterface"

 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #0
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: Call#0 Retry#0 findName(20235010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57528 for RpcKind RPC_WRITABLE
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:ÔèѩÇà (auth:SIMPLE) from:org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - Served: findName queueTime= 0 procesingTime= 1
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20235010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57528
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20235010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57528 Wrote 130 bytes.
 DEBUG IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà got value #0
 DEBUG main org.apache.hadoop.ipc.RPC - Call: findName 111
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: readAndProcess from client 127.0.0.1:57528 threw exception [java.io.IOException: 远程主机强迫关闭了一个现有的连接。]
 java.io.IOException: 远程主机强迫关闭了一个现有的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.ipc.Server.channelRead(Server.java:3262)
	at org.apache.hadoop.ipc.Server.access$2600(Server.java:137)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2037)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1242)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1098)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1069)
DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: disconnecting client 127.0.0.1:57528. Number of active connections: 0
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@4d50efb8
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@77ec78b9
 DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
 DEBUG main org.apache.hadoop.ipc.Client - Connecting to localhost/127.0.0.1:12345
 DEBUG IPC Server listener on 12345 org.apache.hadoop.ipc.Server - Server connection from 127.0.0.1:57537; # active connections: 1; # queued calls: 0
 DEBUG IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà: starting, having connections 1
 DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà sending #0 findName(20210735010150), rpc version=2, client version=1, methodsFingerPrint=1436578371
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #-3
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Successfully authorized userInfo {
  effectiveUser: "\303\224\303\250\321\251\303\207\303\240"
}
protocol: "jike.HadoopRPC.MyInterface"

 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #0
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: Call#0 Retry#0 findName(20210735010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57537 for RpcKind RPC_WRITABLE
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:ÔèѩÇà (auth:SIMPLE) from:org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - Served: findName queueTime= 0 procesingTime= 1
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210735010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57537
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210735010150), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:57537 Wrote 60 bytes.
 DEBUG IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (381707837) connection to localhost/127.0.0.1:12345 from ÔèѩÇà got value #0
 DEBUG main org.apache.hadoop.ipc.RPC - Call: findName 108
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: readAndProcess from client 127.0.0.1:57537 threw exception [java.io.IOException: 远程主机强迫关闭了一个现有的连接。]
 java.io.IOException: 远程主机强迫关闭了一个现有的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.ipc.Server.channelRead(Server.java:3262)
	at org.apache.hadoop.ipc.Server.access$2600(Server.java:137)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2037)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1242)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1098)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1069)
DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: disconnecting client 127.0.0.1:57537. Number of active connections: 0
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
 DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@7e2d773b
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@1a3869f4
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_WRITABLE, rpcRequestWrapperClass=class org.apache.hadoop.ipc.WritableRpcEngine$Invocation, rpcInvoker=org.apache.hadoop.ipc.WritableRpcEngine$Server$WritableRpcInvoker@4c203ea1
 INFO main org.apache.hadoop.ipc.CallQueueManager - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
 DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
 DEBUG main org.apache.hadoop.ipc.Server - Server accepts auth methods:[SIMPLE]
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Starting Socket Reader #1 for port 12345
 DEBUG main org.apache.hadoop.ipc.metrics.RpcMetrics - Initialized MetricsRegistry{info=MetricsInfoImpl{name=rpc, description=rpc}, tags=[MetricsTag{info=MetricsInfoImpl{name=port, description=RPC port}, value=12345}], metrics=[]}
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.receivedBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of received bytes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.sentBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of sent bytes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.rpcQueueTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Queue time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.rpcProcessingTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Processing time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.ipc.metrics.RpcMetrics.deferredRpcProcessingTime with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Deferred Processing time], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthenticationFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of authentication failures], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthenticationSuccesses with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of authentication successes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthorizationFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of authorization failures], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcAuthorizationSuccesses with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of authorization successes], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcClientBackoff with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of client backoff requests], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.ipc.metrics.RpcMetrics.rpcSlowCalls with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of Slow RPC calls], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public java.lang.String org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnectionsPerUser() with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of open connections per user], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public int org.apache.hadoop.ipc.metrics.RpcMetrics.numOpenConnections() with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of open connections], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public long org.apache.hadoop.ipc.metrics.RpcMetrics.numDroppedConnections() with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Number of dropped connections], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - method public int org.apache.hadoop.ipc.metrics.RpcMetrics.callQueueLength() with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Length of the call queue], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - RpcActivityForPort12345, Aggregate RPC metrics
 DEBUG main org.apache.hadoop.ipc.metrics.RpcDetailedMetrics - MetricsInfoImpl{name=rpcdetailed, description=rpcdetailed}
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.rates with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation org.apache.hadoop.ipc.metrics.RpcDetailedMetrics.deferredRpcRates with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - RpcDetailedActivityForPort12345, Per method RPC metrics
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.ipc.Server - RpcKind = RPC_PROTOCOL_BUFFER Protocol Name = org.apache.hadoop.ipc.ProtocolMetaInfoPB version=1 ProtocolImpl=org.apache.hadoop.ipc.protobuf.ProtocolInfoProtos$ProtocolInfoService$2 protocolClass=org.apache.hadoop.ipc.ProtocolMetaInfoPB
 DEBUG main org.apache.hadoop.ipc.Server - RpcKind = RPC_WRITABLE Protocol Name = jike.HadoopRPC.MyInterface version=1 ProtocolImpl=jike.HadoopRPC.Impl.MyInterfaceImpl protocolClass=jike.HadoopRPC.MyInterface
 INFO IPC Server Responder org.apache.hadoop.ipc.Server - IPC Server Responder: starting
 INFO IPC Server listener on 12345 org.apache.hadoop.ipc.Server - IPC Server listener on 12345: starting
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: starting
 DEBUG main org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
 DEBUG main org.apache.hadoop.ipc.Client - Connecting to localhost/127.0.0.1:12345
 DEBUG IPC Server listener on 12345 org.apache.hadoop.ipc.Server - Server connection from 127.0.0.1:50930; # active connections: 1; # queued calls: 0
 DEBUG IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà: starting, having connections 1
 DEBUG IPC Parameter Sending Thread #0 org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà sending #0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #-3
 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Successfully authorized userInfo {
  effectiveUser: "\303\224\303\250\321\251\303\207\303\240"
}
protocol: "jike.HadoopRPC.MyInterface"

 DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server -  got #0
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:50930 for RpcKind RPC_WRITABLE
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.security.UserGroupInformation - PrivilegedAction as:ÔèѩÇà (auth:SIMPLE) from:org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - add
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - findName
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - add
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.metrics2.lib.MutableRatesWithAggregation - findName
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - Served: findName queueTime= 6 procesingTime= 11
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:50930
 DEBUG IPC Server handler 0 on 12345 org.apache.hadoop.ipc.Server - IPC Server handler 0 on 12345: responding to Call#0 Retry#0 findName(20210123456789), rpc version=2, client version=1, methodsFingerPrint=1436578371 from 127.0.0.1:50930 Wrote 57 bytes.
 DEBUG IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà org.apache.hadoop.ipc.Client - IPC Client (589446616) connection to localhost/127.0.0.1:12345 from ÔèѩÇà got value #0
 DEBUG main org.apache.hadoop.ipc.RPC - Call: findName 198
 INFO Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: readAndProcess from client 127.0.0.1:50930 threw exception [java.io.IOException: 远程主机强迫关闭了一个现有的连接。]
 java.io.IOException: 远程主机强迫关闭了一个现有的连接。
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.ipc.Server.channelRead(Server.java:3262)
	at org.apache.hadoop.ipc.Server.access$2600(Server.java:137)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:2037)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:1242)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1098)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1069)
DEBUG Socket Reader #1 for port 12345 org.apache.hadoop.ipc.Server - Socket Reader #1 for port 12345: disconnecting client 127.0.0.1:50930. Number of active connections: 0
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG IPC Server idle connection scanner for port 12345 org.apache.hadoop.ipc.Server - IPC Server idle connection scanner for port 12345: task running
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x37e547da to 47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter\5.8.0-M1\junit-jupiter-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-api\5.8.0-M1\junit-jupiter-api-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\apiguardian\apiguardian-api\1.1.1\apiguardian-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-commons\1.8.0-M1\junit-platform-commons-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-params\5.8.0-M1\junit-jupiter-params-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-engine\5.8.0-M1\junit-jupiter-engine-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-engine\1.8.0-M1\junit-platform-engine-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk8\1.4.20\kotlin-stdlib-jdk8-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib\1.4.20\kotlin-stdlib-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-common\1.4.20\kotlin-stdlib-common-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\annotations\13.0\annotations-13.0.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk7\1.4.20\kotlin-stdlib-jdk7-1.4.20.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/1697591263@65f213eb
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.206.249/47.101.206.249:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.206.249/47.101.206.249:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.206.249/47.101.206.249:2181
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.206.249/47.101.206.249:2181, sessionid = 0x17a8fa62b6c8bd6, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bd6, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590357638,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3aefe5e5
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@123ef382, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bd6, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590357654,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:907)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1302)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1255)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bd6, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 3,4  replyHeader:: 3,8590357654,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bd6, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 4,4  replyHeader:: 4,8590357654,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bd6, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 5,4  replyHeader:: 5,8590357654,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bd6, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 6,4  replyHeader:: 6,8590357654,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bd6, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 7,4  replyHeader:: 7,8590357654,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bd6, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 8,4  replyHeader:: 8,8590357654,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=6, retries=16, started=6631 ms ago, cancelled=false, msg=java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createAddr(AbstractRpcClient.java:430)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createBlockingRpcChannel(AbstractRpcClient.java:507)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.lambda$makeStubNoRetries$0(ConnectionImplementation.java:1132)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker$$Lambda$21/1990519794.get(Unknown Source)
	at org.apache.hadoop.hbase.util.CollectionUtils.computeIfAbsentEx(CollectionUtils.java:61)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1131)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	... 12 more

DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x37e547da to 47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter\5.8.0-M1\junit-jupiter-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-api\5.8.0-M1\junit-jupiter-api-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\apiguardian\apiguardian-api\1.1.1\apiguardian-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-commons\1.8.0-M1\junit-platform-commons-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-params\5.8.0-M1\junit-jupiter-params-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-engine\5.8.0-M1\junit-jupiter-engine-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-engine\1.8.0-M1\junit-platform-engine-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk8\1.4.20\kotlin-stdlib-jdk8-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib\1.4.20\kotlin-stdlib-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-common\1.4.20\kotlin-stdlib-common-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\annotations\13.0\annotations-13.0.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk7\1.4.20\kotlin-stdlib-jdk7-1.4.20.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/987743116@72a90b59
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.206.249/47.101.206.249:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.206.249/47.101.206.249:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.206.249/47.101.206.249:2181
INFO ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.206.249/47.101.206.249:2181, sessionid = 0x17a8fa62b6c8bde, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bde, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590357717,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3aefe5e5
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@123ef382, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bde, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590357717,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@642a7222
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 1084 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bde, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 3,4  replyHeader:: 3,8590357717,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x17a8fa62b6c8bde after 21ms
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bde, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 4,4  replyHeader:: 4,8590357717,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bde, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 5,4  replyHeader:: 5,8590357717,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bde, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 6,4  replyHeader:: 6,8590357717,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bde, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 7,4  replyHeader:: 7,8590357717,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG Default-IPC-NioEventLoopGroup-1-2 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bde, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 8,4  replyHeader:: 8,8590357719,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x17a8fa62b6c8bde after 21ms
DEBUG Default-IPC-NioEventLoopGroup-1-3 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=6, retries=16, started=35326 ms ago, cancelled=false, msg=java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x17a8fa62b6c8bde after 20ms
DEBUG ReadOnlyZKClient-47.101.206.249:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bde, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 9,4  replyHeader:: 9,8590357719,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x37e547da to 47.101.216.12:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter\5.8.0-M1\junit-jupiter-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-api\5.8.0-M1\junit-jupiter-api-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\apiguardian\apiguardian-api\1.1.1\apiguardian-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-commons\1.8.0-M1\junit-platform-commons-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-params\5.8.0-M1\junit-jupiter-params-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-engine\5.8.0-M1\junit-jupiter-engine-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-engine\1.8.0-M1\junit-platform-engine-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk8\1.4.20\kotlin-stdlib-jdk8-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib\1.4.20\kotlin-stdlib-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-common\1.4.20\kotlin-stdlib-common-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\annotations\13.0\annotations-13.0.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk7\1.4.20\kotlin-stdlib-jdk7-1.4.20.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.216.12:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/987743116@72a90b59
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.216.12/47.101.216.12:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.216.12/47.101.216.12:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.216.12/47.101.216.12:2181
INFO ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.216.12/47.101.216.12:2181, sessionid = 0x27a8fa62b6c8c0d, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590357758,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3aefe5e5
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@123ef382, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590357758,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@642a7222
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 20412 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 3,4  replyHeader:: 3,8590357758,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c0d after 27ms
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 4,4  replyHeader:: 4,8590357758,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 5,4  replyHeader:: 5,8590357758,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 6,4  replyHeader:: 6,8590357758,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 7,4  replyHeader:: 7,8590357758,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG Default-IPC-NioEventLoopGroup-1-2 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 8,4  replyHeader:: 8,8590357760,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c0d after 22ms
DEBUG Default-IPC-NioEventLoopGroup-1-3 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=6, retries=16, started=35273 ms ago, cancelled=false, msg=java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c0d after 21ms
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 9,4  replyHeader:: 9,8590357760,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG Default-IPC-NioEventLoopGroup-1-4 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=7, retries=16, started=49334 ms ago, cancelled=false, msg=java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c0d after 22ms
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 10,4  replyHeader:: 10,8590357776,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG Default-IPC-NioEventLoopGroup-1-5 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=8, retries=16, started=69449 ms ago, cancelled=false, msg=java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c0d after 21ms
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 11,4  replyHeader:: 11,8590357776,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG Default-IPC-NioEventLoopGroup-1-6 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=9, retries=16, started=89521 ms ago, cancelled=false, msg=java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c0d after 22ms
DEBUG ReadOnlyZKClient-47.101.216.12:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c0d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 12,4  replyHeader:: 12,8590357778,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x37e547da to jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter\5.8.0-M1\junit-jupiter-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-api\5.8.0-M1\junit-jupiter-api-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\apiguardian\apiguardian-api\1.1.1\apiguardian-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-commons\1.8.0-M1\junit-platform-commons-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-params\5.8.0-M1\junit-jupiter-params-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-engine\5.8.0-M1\junit-jupiter-engine-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-engine\1.8.0-M1\junit-platform-engine-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk8\1.4.20\kotlin-stdlib-jdk8-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib\1.4.20\kotlin-stdlib-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-common\1.4.20\kotlin-stdlib-common-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\annotations\13.0\annotations-13.0.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk7\1.4.20\kotlin-stdlib-jdk7-1.4.20.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/1697591263@65f213eb
DEBUG ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da-SendThread(jikehadoop03:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server jikehadoop03/172.16.63.15:2181. Will not attempt to authenticate using SASL (unknown error)
WARN ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da-SendThread(jikehadoop03:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
DEBUG ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da-SendThread(jikehadoop03:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780)
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170)
DEBUG ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da-SendThread(jikehadoop03:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170)
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da-SendThread(jikehadoop02:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server jikehadoop02/172.16.63.14:2181. Will not attempt to authenticate using SASL (unknown error)
WARN ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - 0x37e547da to jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181 failed for get of /hbase/hbaseid, code = CONNECTIONLOSS, retries = 1
WARN ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da-SendThread(jikehadoop02:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
DEBUG ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da-SendThread(jikehadoop02:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780)
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170)
DEBUG ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da-SendThread(jikehadoop02:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170)
WARN ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - 0x37e547da to jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181 failed for get of /hbase/hbaseid, code = CONNECTIONLOSS, retries = 2
INFO ReadOnlyZKClient-jikehadoop01:2181,jikehadoop02:2181,jikehadoop03:2181@0x37e547da-SendThread(jikehadoop01:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server jikehadoop01/172.16.63.17:2181. Will not attempt to authenticate using SASL (unknown error)
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x37e547da to 172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter\5.8.0-M1\junit-jupiter-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-api\5.8.0-M1\junit-jupiter-api-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\apiguardian\apiguardian-api\1.1.1\apiguardian-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-commons\1.8.0-M1\junit-platform-commons-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-params\5.8.0-M1\junit-jupiter-params-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-engine\5.8.0-M1\junit-jupiter-engine-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-engine\1.8.0-M1\junit-platform-engine-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk8\1.4.20\kotlin-stdlib-jdk8-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib\1.4.20\kotlin-stdlib-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-common\1.4.20\kotlin-stdlib-common-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\annotations\13.0\annotations-13.0.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk7\1.4.20\kotlin-stdlib-jdk7-1.4.20.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/177165992@22c54a98
DEBUG ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.15:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 172.16.63.15/172.16.63.15:2181. Will not attempt to authenticate using SASL (unknown error)
WARN ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.15:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
DEBUG ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.15:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780)
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170)
DEBUG ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.15:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170)
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.17:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 172.16.63.17/172.16.63.17:2181. Will not attempt to authenticate using SASL (unknown error)
WARN ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - 0x37e547da to 172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181 failed for get of /hbase/hbaseid, code = CONNECTIONLOSS, retries = 1
WARN ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.17:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
DEBUG ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.17:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780)
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170)
DEBUG ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.17:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170)
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.14:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 172.16.63.14/172.16.63.14:2181. Will not attempt to authenticate using SASL (unknown error)
WARN ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - 0x37e547da to 172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181 failed for get of /hbase/hbaseid, code = CONNECTIONLOSS, retries = 2
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x37e547da to 172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter\5.8.0-M1\junit-jupiter-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-api\5.8.0-M1\junit-jupiter-api-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\apiguardian\apiguardian-api\1.1.1\apiguardian-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-commons\1.8.0-M1\junit-platform-commons-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-params\5.8.0-M1\junit-jupiter-params-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-engine\5.8.0-M1\junit-jupiter-engine-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-engine\1.8.0-M1\junit-platform-engine-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk8\1.4.20\kotlin-stdlib-jdk8-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib\1.4.20\kotlin-stdlib-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-common\1.4.20\kotlin-stdlib-common-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\annotations\13.0\annotations-13.0.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk7\1.4.20\kotlin-stdlib-jdk7-1.4.20.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/1542401088@3b3a5f41
DEBUG ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.15:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 172.16.63.15/172.16.63.15:2181. Will not attempt to authenticate using SASL (unknown error)
WARN ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.15:2181) org.apache.zookeeper.ClientCnxn - Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection timed out: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:361)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1141)
DEBUG ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.15:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown input
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownInput(SocketChannelImpl.java:780)
	at sun.nio.ch.SocketAdaptor.shutdownInput(SocketAdaptor.java:402)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:200)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170)
DEBUG ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.15:2181) org.apache.zookeeper.ClientCnxnSocketNIO - Ignoring exception during shutdown output
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.shutdownOutput(SocketChannelImpl.java:797)
	at sun.nio.ch.SocketAdaptor.shutdownOutput(SocketAdaptor.java:410)
	at org.apache.zookeeper.ClientCnxnSocketNIO.cleanup(ClientCnxnSocketNIO.java:207)
	at org.apache.zookeeper.ClientCnxn$SendThread.cleanup(ClientCnxn.java:1246)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1170)
INFO ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da-SendThread(172.16.63.17:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 172.16.63.17/172.16.63.17:2181. Will not attempt to authenticate using SASL (unknown error)
WARN ReadOnlyZKClient-172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181@0x37e547da org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - 0x37e547da to 172.16.63.17:2181,172.16.63.14:2181,172.16.63.15:2181 failed for get of /hbase/hbaseid, code = CONNECTIONLOSS, retries = 1
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x37e547da to 47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter\5.8.0-M1\junit-jupiter-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-api\5.8.0-M1\junit-jupiter-api-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\apiguardian\apiguardian-api\1.1.1\apiguardian-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-commons\1.8.0-M1\junit-platform-commons-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-params\5.8.0-M1\junit-jupiter-params-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-engine\5.8.0-M1\junit-jupiter-engine-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-engine\1.8.0-M1\junit-platform-engine-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk8\1.4.20\kotlin-stdlib-jdk8-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib\1.4.20\kotlin-stdlib-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-common\1.4.20\kotlin-stdlib-common-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\annotations\13.0\annotations-13.0.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk7\1.4.20\kotlin-stdlib-jdk7-1.4.20.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/2033440568@648e61e5
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.206.249/47.101.206.249:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.206.249/47.101.206.249:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.206.249/47.101.206.249:2181
INFO ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.206.249/47.101.206.249:2181, sessionid = 0x17a8fa62b6c8bf0, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bf0, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590357922,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3aefe5e5
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@123ef382, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bf0, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590357922,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@642a7222
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 4128 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bf0, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 3,4  replyHeader:: 3,8590357924,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x17a8fa62b6c8bf0 after 23ms
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bf0, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 4,4  replyHeader:: 4,8590357924,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bf0, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 5,4  replyHeader:: 5,8590357924,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bf0, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 6,4  replyHeader:: 6,8590357924,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bf0, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 7,4  replyHeader:: 7,8590357924,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG Default-IPC-NioEventLoopGroup-1-2 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bf0, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 8,4  replyHeader:: 8,8590357924,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x17a8fa62b6c8bf0 after 22ms
DEBUG Default-IPC-NioEventLoopGroup-1-3 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=6, retries=16, started=35242 ms ago, cancelled=false, msg=java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:66)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:69)
Caused by: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x17a8fa62b6c8bf0 after 22ms
DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8bf0, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 9,4  replyHeader:: 9,8590357940,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG Default-IPC-NioEventLoopGroup-1-4 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=7, retries=16, started=49277 ms ago, cancelled=false, msg=java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:66)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:69)
Caused by: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.206.249:2181,47.101.216.12:2181,47.101.204.23:2181@0x37e547da-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x17a8fa62b6c8bf0 after 22ms
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x37e547da to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter\5.8.0-M1\junit-jupiter-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-api\5.8.0-M1\junit-jupiter-api-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\apiguardian\apiguardian-api\1.1.1\apiguardian-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-commons\1.8.0-M1\junit-platform-commons-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-params\5.8.0-M1\junit-jupiter-params-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-engine\5.8.0-M1\junit-jupiter-engine-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-engine\1.8.0-M1\junit-platform-engine-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk8\1.4.20\kotlin-stdlib-jdk8-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib\1.4.20\kotlin-stdlib-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-common\1.4.20\kotlin-stdlib-common-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\annotations\13.0\annotations-13.0.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk7\1.4.20\kotlin-stdlib-jdk7-1.4.20.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/2033440568@648e61e5
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.216.12/47.101.216.12:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.216.12/47.101.216.12:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.216.12/47.101.216.12:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.216.12/47.101.216.12:2181, sessionid = 0x27a8fa62b6c8c1c, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590357980,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3aefe5e5
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@123ef382, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590357980,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:907)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1302)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1255)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 3,4  replyHeader:: 3,8590357980,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 4,4  replyHeader:: 4,8590357980,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 5,4  replyHeader:: 5,8590357980,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 6,4  replyHeader:: 6,8590357980,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 7,4  replyHeader:: 7,8590357980,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 8,4  replyHeader:: 8,8590357980,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=6, retries=16, started=6619 ms ago, cancelled=false, msg=java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createAddr(AbstractRpcClient.java:430)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createBlockingRpcChannel(AbstractRpcClient.java:507)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.lambda$makeStubNoRetries$0(ConnectionImplementation.java:1132)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker$$Lambda$21/1990519794.get(Unknown Source)
	at org.apache.hadoop.hbase.util.CollectionUtils.computeIfAbsentEx(CollectionUtils.java:61)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1131)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	... 12 more

DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 9,4  replyHeader:: 9,8590357980,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=7, retries=16, started=10654 ms ago, cancelled=false, msg=java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createAddr(AbstractRpcClient.java:430)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createBlockingRpcChannel(AbstractRpcClient.java:507)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.lambda$makeStubNoRetries$0(ConnectionImplementation.java:1132)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker$$Lambda$21/1990519794.get(Unknown Source)
	at org.apache.hadoop.hbase.util.CollectionUtils.computeIfAbsentEx(CollectionUtils.java:61)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1131)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	... 12 more

DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 10,4  replyHeader:: 10,8590357996,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c1c after 20ms
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:907)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1302)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1255)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=8, retries=16, started=22937 ms ago, cancelled=false, msg=java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createAddr(AbstractRpcClient.java:430)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createBlockingRpcChannel(AbstractRpcClient.java:507)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.lambda$makeStubNoRetries$0(ConnectionImplementation.java:1132)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker$$Lambda$21/1990519794.get(Unknown Source)
	at org.apache.hadoop.hbase.util.CollectionUtils.computeIfAbsentEx(CollectionUtils.java:61)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1131)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	... 12 more

DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 11,4  replyHeader:: 11,8590357996,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c1c after 20ms
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:907)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1302)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1255)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=9, retries=16, started=35213 ms ago, cancelled=false, msg=java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createAddr(AbstractRpcClient.java:430)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createBlockingRpcChannel(AbstractRpcClient.java:507)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.lambda$makeStubNoRetries$0(ConnectionImplementation.java:1132)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker$$Lambda$21/1990519794.get(Unknown Source)
	at org.apache.hadoop.hbase.util.CollectionUtils.computeIfAbsentEx(CollectionUtils.java:61)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1131)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	... 12 more

DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c1c, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 12,4  replyHeader:: 12,8590357998,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c1c after 20ms
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop02, please check your network
java.net.UnknownHostException: jikehadoop02
	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:907)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1302)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1255)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1129)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=10, retries=16, started=47521 ms ago, cancelled=false, msg=java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.UnknownHostException: can not resolve jikehadoop02,16000,1627199314951
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createAddr(AbstractRpcClient.java:430)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.createBlockingRpcChannel(AbstractRpcClient.java:507)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.lambda$makeStubNoRetries$0(ConnectionImplementation.java:1132)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker$$Lambda$21/1990519794.get(Unknown Source)
	at org.apache.hadoop.hbase.util.CollectionUtils.computeIfAbsentEx(CollectionUtils.java:61)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStubNoRetries(ConnectionImplementation.java:1131)
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1151)
	... 12 more

DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x37e547da to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter\5.8.0-M1\junit-jupiter-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-api\5.8.0-M1\junit-jupiter-api-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\apiguardian\apiguardian-api\1.1.1\apiguardian-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\org\opentest4j\opentest4j\1.2.0\opentest4j-1.2.0.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-commons\1.8.0-M1\junit-platform-commons-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-params\5.8.0-M1\junit-jupiter-params-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\jupiter\junit-jupiter-engine\5.8.0-M1\junit-jupiter-engine-5.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\junit\platform\junit-platform-engine\1.8.0-M1\junit-platform-engine-1.8.0-M1.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk8\1.4.20\kotlin-stdlib-jdk8-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib\1.4.20\kotlin-stdlib-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-common\1.4.20\kotlin-stdlib-common-1.4.20.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\annotations\13.0\annotations-13.0.jar;D:\install\big_data\maven\maven\repo\org\jetbrains\kotlin\kotlin-stdlib-jdk7\1.4.20\kotlin-stdlib-jdk7-1.4.20.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/987743116@72a90b59
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.204.23/47.101.204.23:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.204.23/47.101.204.23:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.204.23/47.101.204.23:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.204.23/47.101.204.23:2181, sessionid = 0x37a8fa62b708bc8, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bc8, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358070,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3aefe5e5
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@123ef382, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bc8, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590358070,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@642a7222
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 20044 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bc8, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 3,4  replyHeader:: 3,8590358072,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x37a8fa62b708bc8 after 20ms
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bc8, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 4,4  replyHeader:: 4,8590358072,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bc8, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 5,4  replyHeader:: 5,8590358072,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bc8, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 6,4  replyHeader:: 6,8590358072,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop02/172.16.63.14:16000 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bc8, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 7,4  replyHeader:: 7,8590358072,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG Default-IPC-NioEventLoopGroup-1-2 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bc8, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 8,4  replyHeader:: 8,8590358088,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x37a8fa62b708bc8 after 20ms
DEBUG Default-IPC-NioEventLoopGroup-1-3 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop02/172.16.63.14:16000 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=6, retries=16, started=35257 ms ago, cancelled=false, msg=java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000, details=, exception=org.apache.hadoop.hbase.MasterNotRunningException: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.client.ConnectionImplementation$MasterServiceStubMaker.makeStub(ConnectionImplementation.java:1157)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getKeepAliveMasterService(ConnectionImplementation.java:1216)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getMaster(ConnectionImplementation.java:1205)
	at org.apache.hadoop.hbase.client.MasterCallable.prepare(MasterCallable.java:57)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTableAsync(HBaseAdmin.java:647)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:620)
	at org.apache.hadoop.hbase.client.HBaseAdmin.createTable(HBaseAdmin.java:594)
	at jike.JavaApi_Hbase.CreateTable.create(CreateTable.java:28)
	at jike.JavaApi_Hbase.Hbase.create(Hbase.java:65)
	at jike.JavaApi_Hbase.Hbase.main(Hbase.java:68)
Caused by: java.net.ConnectException: Call to jikehadoop02/172.16.63.14:16000 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop02/172.16.63.14:16000
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x37a8fa62b708bc8 after 19ms
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x37e547da-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bc8, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 9,4  replyHeader:: 9,8590358088,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x6f3b5d16 to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/615403774@2620a897
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.216.12/47.101.216.12:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.216.12/47.101.216.12:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.216.12/47.101.216.12:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.216.12/47.101.216.12:2181, sessionid = 0x27a8fa62b6c8c3a, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358252,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@7adda9cc
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@393671df, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 2,4  replyHeader:: 2,8590358252,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@9816741
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 14164 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop05/172.16.63.16:16020 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 3,4  replyHeader:: 3,8590358252,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c3a after 20ms
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop05/172.16.63.16:16020 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 4,4  replyHeader:: 4,8590358252,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop05/172.16.63.16:16020 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 5,4  replyHeader:: 5,8590358252,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop05/172.16.63.16:16020 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 6,4  replyHeader:: 6,8590358252,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Not trying to connect to jikehadoop05/172.16.63.16:16020 this server is in the failed servers list
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 7,4  replyHeader:: 7,8590358252,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG Default-IPC-NioEventLoopGroup-1-2 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop05/172.16.63.16:16020 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 8,4  replyHeader:: 8,8590358252,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c3a after 20ms
DEBUG Default-IPC-NioEventLoopGroup-1-3 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop05/172.16.63.16:16020 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=6, retries=16, started=35416 ms ago, cancelled=false, msg=Call to jikehadoop05/172.16.63.16:16020 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020, details=row 'percentOne_test:student' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=jikehadoop05,16020,1627199325811, seqNum=-1, exception=java.net.ConnectException: Call to jikehadoop05/172.16.63.16:16020 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c3a after 19ms
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 9,4  replyHeader:: 9,8590358254,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG Default-IPC-NioEventLoopGroup-1-4 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop05/172.16.63.16:16020 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=7, retries=16, started=49459 ms ago, cancelled=false, msg=Call to jikehadoop05/172.16.63.16:16020 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020, details=row 'percentOne_test:student' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=jikehadoop05,16020,1627199325811, seqNum=-1, exception=java.net.ConnectException: Call to jikehadoop05/172.16.63.16:16020 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c3a after 18ms
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 10,4  replyHeader:: 10,8590358270,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG Default-IPC-NioEventLoopGroup-1-5 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop05/172.16.63.16:16020 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=8, retries=16, started=69570 ms ago, cancelled=false, msg=Call to jikehadoop05/172.16.63.16:16020 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020, details=row 'percentOne_test:student' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=jikehadoop05,16020,1627199325811, seqNum=-1, exception=java.net.ConnectException: Call to jikehadoop05/172.16.63.16:16020 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c3a after 19ms
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c3a, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 11,4  replyHeader:: 11,8590358270,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG Default-IPC-NioEventLoopGroup-1-6 org.apache.hadoop.hbase.ipc.FailedServers - Added failed server with address jikehadoop05/172.16.63.16:16020 to list caused by org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
DEBUG main org.apache.hadoop.hbase.client.RpcRetryingCallerImpl - Call exception, tries=9, retries=16, started=89673 ms ago, cancelled=false, msg=Call to jikehadoop05/172.16.63.16:16020 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020, details=row 'percentOne_test:student' on table 'hbase:meta' at region=hbase:meta,,1.1588230740, hostname=jikehadoop05,16020,1627199325811, seqNum=-1, exception=java.net.ConnectException: Call to jikehadoop05/172.16.63.16:16020 failed on connection exception: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
	at org.apache.hadoop.hbase.ipc.IPCUtil.wrapException(IPCUtil.java:165)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.onCallFinished(AbstractRpcClient.java:390)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$100(AbstractRpcClient.java:95)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:410)
	at org.apache.hadoop.hbase.ipc.AbstractRpcClient$3.run(AbstractRpcClient.java:406)
	at org.apache.hadoop.hbase.ipc.Call.callComplete(Call.java:103)
	at org.apache.hadoop.hbase.ipc.Call.setException(Call.java:118)
	at org.apache.hadoop.hbase.ipc.BufferCallBeforeInitHandler.userEventTriggered(BufferCallBeforeInitHandler.java:92)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.fireUserEventTriggered(AbstractChannelHandlerContext.java:307)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline$HeadContext.userEventTriggered(DefaultChannelPipeline.java:1377)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:329)
	at org.apache.hbase.thirdparty.io.netty.channel.AbstractChannelHandlerContext.invokeUserEventTriggered(AbstractChannelHandlerContext.java:315)
	at org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelPipeline.fireUserEventTriggered(DefaultChannelPipeline.java:929)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.failInit(NettyRpcConnection.java:179)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection.access$500(NettyRpcConnection.java:71)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:267)
	at org.apache.hadoop.hbase.ipc.NettyRpcConnection$3.operationComplete(NettyRpcConnection.java:261)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:507)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners0(DefaultPromise.java:500)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:479)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:420)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:122)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:269)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:120)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.apache.hbase.thirdparty.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hbase.thirdparty.io.netty.channel.ConnectTimeoutException: connection timed out: jikehadoop05/172.16.63.16:16020
	at org.apache.hbase.thirdparty.io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe$1.run(AbstractNioChannel.java:267)
	... 8 more

DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x27a8fa62b6c8c3a after 19ms
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x6f3b5d16 to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/615403774@2620a897
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.204.23/47.101.204.23:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.204.23/47.101.204.23:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.204.23/47.101.204.23:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.204.23/47.101.204.23:2181, sessionid = 0x37a8fa62b708bdc, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bdc, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358273,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@7adda9cc
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@393671df, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bdc, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 2,4  replyHeader:: 2,8590358273,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop05, please check your network
java.net.UnknownHostException: jikehadoop05
	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:907)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1302)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1255)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getClient(ConnectionImplementation.java:1192)
	at org.apache.hadoop.hbase.client.ClientServiceCallable.setStubByServiceName(ClientServiceCallable.java:44)
	at org.apache.hadoop.hbase.client.RegionServerCallable.prepare(RegionServerCallable.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:386)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:360)
	at org.apache.hadoop.hbase.MetaTableAccessor.getTableState(MetaTableAccessor.java:1078)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:403)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:445)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:442)
	at org.apache.hadoop.hbase.client.RpcRetryingCallable.call(RpcRetryingCallable.java:58)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:442)
	at jike.JavaApi_Hbase.HBaseDemo.creatTable(HBaseDemo.java:73)
	at jike.JavaApi_Hbase.HBaseDemo.main(HBaseDemo.java:47)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bdc, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 3,4  replyHeader:: 3,8590358273,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop05, please check your network
java.net.UnknownHostException: jikehadoop05
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getClient(ConnectionImplementation.java:1192)
	at org.apache.hadoop.hbase.client.ClientServiceCallable.setStubByServiceName(ClientServiceCallable.java:44)
	at org.apache.hadoop.hbase.client.RegionServerCallable.prepare(RegionServerCallable.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:386)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:360)
	at org.apache.hadoop.hbase.MetaTableAccessor.getTableState(MetaTableAccessor.java:1078)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:403)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:445)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:442)
	at org.apache.hadoop.hbase.client.RpcRetryingCallable.call(RpcRetryingCallable.java:58)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:442)
	at jike.JavaApi_Hbase.HBaseDemo.creatTable(HBaseDemo.java:73)
	at jike.JavaApi_Hbase.HBaseDemo.main(HBaseDemo.java:47)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bdc, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 4,4  replyHeader:: 4,8590358273,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop05, please check your network
java.net.UnknownHostException: jikehadoop05
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getClient(ConnectionImplementation.java:1192)
	at org.apache.hadoop.hbase.client.ClientServiceCallable.setStubByServiceName(ClientServiceCallable.java:44)
	at org.apache.hadoop.hbase.client.RegionServerCallable.prepare(RegionServerCallable.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:386)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:360)
	at org.apache.hadoop.hbase.MetaTableAccessor.getTableState(MetaTableAccessor.java:1078)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:403)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:445)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:442)
	at org.apache.hadoop.hbase.client.RpcRetryingCallable.call(RpcRetryingCallable.java:58)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:442)
	at jike.JavaApi_Hbase.HBaseDemo.creatTable(HBaseDemo.java:73)
	at jike.JavaApi_Hbase.HBaseDemo.main(HBaseDemo.java:47)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bdc, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 5,4  replyHeader:: 5,8590358273,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop05, please check your network
java.net.UnknownHostException: jikehadoop05
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getClient(ConnectionImplementation.java:1192)
	at org.apache.hadoop.hbase.client.ClientServiceCallable.setStubByServiceName(ClientServiceCallable.java:44)
	at org.apache.hadoop.hbase.client.RegionServerCallable.prepare(RegionServerCallable.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:386)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:360)
	at org.apache.hadoop.hbase.MetaTableAccessor.getTableState(MetaTableAccessor.java:1078)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:403)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:445)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:442)
	at org.apache.hadoop.hbase.client.RpcRetryingCallable.call(RpcRetryingCallable.java:58)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:442)
	at jike.JavaApi_Hbase.HBaseDemo.creatTable(HBaseDemo.java:73)
	at jike.JavaApi_Hbase.HBaseDemo.main(HBaseDemo.java:47)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bdc, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 6,4  replyHeader:: 6,8590358273,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop05, please check your network
java.net.UnknownHostException: jikehadoop05
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getClient(ConnectionImplementation.java:1192)
	at org.apache.hadoop.hbase.client.ClientServiceCallable.setStubByServiceName(ClientServiceCallable.java:44)
	at org.apache.hadoop.hbase.client.RegionServerCallable.prepare(RegionServerCallable.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:386)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:360)
	at org.apache.hadoop.hbase.MetaTableAccessor.getTableState(MetaTableAccessor.java:1078)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:403)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:445)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:442)
	at org.apache.hadoop.hbase.client.RpcRetryingCallable.call(RpcRetryingCallable.java:58)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:442)
	at jike.JavaApi_Hbase.HBaseDemo.creatTable(HBaseDemo.java:73)
	at jike.JavaApi_Hbase.HBaseDemo.main(HBaseDemo.java:47)
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bdc, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 7,4  replyHeader:: 7,8590358273,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
WARN main org.apache.hadoop.hbase.client.ConnectionUtils - Can not resolve jikehadoop05, please check your network
java.net.UnknownHostException: jikehadoop05
	at java.net.InetAddress.getAllByName0(InetAddress.java:1259)
	at java.net.InetAddress.getAllByName(InetAddress.java:1171)
	at java.net.InetAddress.getAllByName(InetAddress.java:1105)
	at java.net.InetAddress.getByName(InetAddress.java:1055)
	at org.apache.hadoop.hbase.client.ConnectionUtils.getStubKey(ConnectionUtils.java:233)
	at org.apache.hadoop.hbase.client.ConnectionImplementation.getClient(ConnectionImplementation.java:1192)
	at org.apache.hadoop.hbase.client.ClientServiceCallable.setStubByServiceName(ClientServiceCallable.java:44)
	at org.apache.hadoop.hbase.client.RegionServerCallable.prepare(RegionServerCallable.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:105)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:386)
	at org.apache.hadoop.hbase.client.HTable.get(HTable.java:360)
	at org.apache.hadoop.hbase.MetaTableAccessor.getTableState(MetaTableAccessor.java:1078)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:403)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:445)
	at org.apache.hadoop.hbase.client.HBaseAdmin$6.rpcCall(HBaseAdmin.java:442)
	at org.apache.hadoop.hbase.client.RpcRetryingCallable.call(RpcRetryingCallable.java:58)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:107)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3084)
	at org.apache.hadoop.hbase.client.HBaseAdmin.executeCallable(HBaseAdmin.java:3076)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:442)
	at jike.JavaApi_Hbase.HBaseDemo.creatTable(HBaseDemo.java:73)
	at jike.JavaApi_Hbase.HBaseDemo.main(HBaseDemo.java:47)
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x6f3b5d16 to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/560064638@64283ffa
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, about=, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, about=, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, about=, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, about=, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, about=, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x6f3b5d16 to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/819923378@6308cf86
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16 org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.216.12/47.101.216.12:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.216.12/47.101.216.12:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.216.12/47.101.216.12:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.216.12/47.101.216.12:2181, sessionid = 0x27a8fa62b6c8c42, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c42, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358328,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@7adda9cc
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@393671df, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c42, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 2,4  replyHeader:: 2,8590358328,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@9816741
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 13464 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 32768
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.linkCapacity: 16
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x6f3b5d16-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c42, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 3,4  replyHeader:: 3,8590358328,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.hadoop.fs.FileSystem - Loading filesystems
DEBUG main org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
DEBUG main org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
DEBUG main org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
DEBUG main org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = none
DEBUG main org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2fc0cc3
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@a776e
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@a776e
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@a776e
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@a776e
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG Thread-4 org.apache.hadoop.util.ShutdownHookManager - ShutdownHookManger complete shutdown.
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/1518687411@4d8dd0a9
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.204.23/47.101.204.23:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.204.23/47.101.204.23:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.204.23/47.101.204.23:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.204.23/47.101.204.23:2181, sessionid = 0x37a8fa62b708be2, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708be2, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358331,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3cc2931c
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7193666c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708be2, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590358331,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@1f9f6368
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 5984 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 32768
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.linkCapacity: 16
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.hadoop.fs.FileSystem - Loading filesystems
DEBUG main org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
DEBUG main org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
DEBUG main org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
DEBUG main org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = none
DEBUG main org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5d1659ea
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@f001896
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
INFO main org.apache.hadoop.hbase.client.ConnectionImplementation - Closing master protocol: MasterService
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Close zookeeper connection 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Stopping rpc client
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Closing session: 0x37a8fa62b708be2
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - Closing client for session: 0x37a8fa62b708be2
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG Thread-4 org.apache.hadoop.util.ShutdownHookManager - ShutdownHookManger complete shutdown.
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x258e2e41 to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/1269215678@762dd5ac
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.204.23/47.101.204.23:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.204.23/47.101.204.23:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.204.23/47.101.204.23:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.204.23/47.101.204.23:2181, sessionid = 0x37a8fa62b708bf5, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bf5, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358548,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3967e60c
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3835c46, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708bf5, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590358548,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@7bd7d6d6
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 20180 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 32768
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.linkCapacity: 16
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.hadoop.fs.FileSystem - Loading filesystems
DEBUG main org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
DEBUG main org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
DEBUG main org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
DEBUG main org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = none
DEBUG main org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@fcb4004
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@8c11eee
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@8c11eee
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@8c11eee
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@8c11eee
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG Thread-4 org.apache.hadoop.util.ShutdownHookManager - ShutdownHookManger complete shutdown.
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/1697591263@65f213eb
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.216.12/47.101.216.12:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.216.12/47.101.216.12:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.216.12/47.101.216.12:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.216.12/47.101.216.12:2181, sessionid = 0x27a8fa62b6c8c5d, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c5d, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358568,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3cc2931c
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7193666c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c5d, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590358568,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@1f9f6368
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 8176 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 32768
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.linkCapacity: 16
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.hadoop.fs.FileSystem - Loading filesystems
DEBUG main org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
DEBUG main org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
DEBUG main org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
DEBUG main org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = none
DEBUG main org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5d1659ea
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@f001896
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
INFO main org.apache.hadoop.hbase.client.ConnectionImplementation - Closing master protocol: MasterService
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Close zookeeper connection 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Stopping rpc client
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Closing session: 0x27a8fa62b6c8c5d
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - Closing client for session: 0x27a8fa62b6c8c5d
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG Thread-4 org.apache.hadoop.util.ShutdownHookManager - ShutdownHookManger complete shutdown.
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x258e2e41 to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/1269215678@762dd5ac
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41 org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.206.249/47.101.206.249:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.206.249/47.101.206.249:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.206.249/47.101.206.249:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.206.249/47.101.206.249:2181, sessionid = 0x17a8fa62b6c8c31, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8c31, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358698,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3967e60c
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3835c46, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x258e2e41-SendThread(47.101.206.249:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x17a8fa62b6c8c31, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590358698,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@7bd7d6d6
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 20228 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 32768
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.linkCapacity: 16
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.hadoop.fs.FileSystem - Loading filesystems
DEBUG main org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
DEBUG main org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
DEBUG main org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
DEBUG main org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = none
DEBUG main org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@56e8b606
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@681a8b4e
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@681a8b4e
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@681a8b4e
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@681a8b4e
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG Thread-4 org.apache.hadoop.util.ShutdownHookManager - ShutdownHookManger complete shutdown.
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/1697591263@65f213eb
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.204.23/47.101.204.23:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.204.23/47.101.204.23:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.204.23/47.101.204.23:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.204.23/47.101.204.23:2181, sessionid = 0x37a8fa62b708c05, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708c05, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358718,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3cc2931c
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7193666c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708c05, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590358718,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@1f9f6368
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 7716 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 32768
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.linkCapacity: 16
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.hadoop.fs.FileSystem - Loading filesystems
DEBUG main org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
DEBUG main org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
DEBUG main org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
DEBUG main org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = none
DEBUG main org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5d1659ea
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@f001896
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
INFO main org.apache.hadoop.hbase.client.ConnectionImplementation - Closing master protocol: MasterService
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Close zookeeper connection 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Stopping rpc client
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Closing session: 0x37a8fa62b708c05
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - Closing client for session: 0x37a8fa62b708c05
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG Thread-4 org.apache.hadoop.util.ShutdownHookManager - ShutdownHookManger complete shutdown.
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, about=, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/2033440568@648e61e5
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.204.23/47.101.204.23:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.204.23/47.101.204.23:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.204.23/47.101.204.23:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.204.23/47.101.204.23:2181, sessionid = 0x37a8fa62b708c07, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708c07, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358736,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3cc2931c
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7193666c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b708c07, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590358736,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@1f9f6368
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 23604 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 32768
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.linkCapacity: 16
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
DEBUG main org.apache.htrace.core.Tracer - sampler.classes = ; loaded no samplers
DEBUG main org.apache.htrace.core.Tracer - span.receiver.classes = ; loaded no span receivers
DEBUG main org.apache.hadoop.fs.FileSystem - Loading filesystems
DEBUG main org.apache.hadoop.fs.FileSystem - file:// = class org.apache.hadoop.fs.LocalFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - ftp:// = class org.apache.hadoop.fs.ftp.FTPFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - har:// = class org.apache.hadoop.fs.HarFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-common/3.0.0/hadoop-common-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /D:/install/big_data/maven/maven/repo/org/apache/hadoop/hadoop-hdfs-client/3.0.0/hadoop-hdfs-client-3.0.0.jar
DEBUG main org.apache.hadoop.fs.FileSystem - Looking for FS supporting hdfs
DEBUG main org.apache.hadoop.fs.FileSystem - looking for configuration option fs.hdfs.impl
DEBUG main org.apache.hadoop.fs.FileSystem - Looking in service filesystems for implementation class
DEBUG main org.apache.hadoop.fs.FileSystem - FS for hdfs is class org.apache.hadoop.hdfs.DistributedFileSystem
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.use.legacy.blockreader.local = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.read.shortcircuit = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.client.domain.socket.data.traffic = false
DEBUG main org.apache.hadoop.hdfs.client.impl.DfsClientConf - dfs.domain.socket.path = none
DEBUG main org.apache.hadoop.hdfs.DFSClient - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcProtobufRequest, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5d1659ea
DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@f001896
DEBUG main org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
DEBUG main org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
INFO main org.apache.hadoop.hbase.client.ConnectionImplementation - Closing master protocol: MasterService
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Close zookeeper connection 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Stopping rpc client
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Closing session: 0x37a8fa62b708c07
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - Closing client for session: 0x37a8fa62b708c07
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@f001896
DEBUG pool-5-thread-1 org.apache.hadoop.ipc.Client - Stopping client
DEBUG Thread-4 org.apache.hadoop.util.ShutdownHookManager - ShutdownHookManger complete shutdown.
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/1269215678@762dd5ac
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.216.12/47.101.216.12:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.216.12/47.101.216.12:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.216.12/47.101.216.12:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.216.12/47.101.216.12:2181, sessionid = 0x27a8fa62b6c8c6b, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c6b, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590358740,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3cc2931c
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7193666c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c8c6b, packet:: clientPath:/hbase/master serverPath:/hbase/master finished:false header:: 2,4  replyHeader:: 2,8590358740,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a31363030304a5b31ffffffb5ffffffebffffff90ffffffecffffffd850425546a18ac6a696b656861646f6f70303210ffffff807d18ffffff87ffffffb8ffffff8cffffffe5ffffffad2f10018ffffff8a7d,s{8590270935,8590270935,1627199319870,1627199319870,0,0,0,178613079090425019,60,0,8590270935} 
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@eadd4fb
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 4880 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG main org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 32768
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.linkCapacity: 16
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Operation: CREATE, Table Name: percentOne:student, procId: 725 completed
INFO main org.apache.hadoop.hbase.client.ConnectionImplementation - Closing master protocol: MasterService
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Close zookeeper connection 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Stopping rpc client
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Closing session: 0x27a8fa62b6c8c6b
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - Closing client for session: 0x27a8fa62b6c8c6b
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/915458523@1b8b6536
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.216.12/47.101.216.12:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.216.12/47.101.216.12:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.216.12/47.101.216.12:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.216.12/47.101.216.12:2181, sessionid = 0x27a8fa62b6c94d5, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.216.12:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x27a8fa62b6c94d5, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590382708,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3cc2931c
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7193666c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, always=false, sampleName=Ops, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/1018405773@60e5ba6c
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.204.23/47.101.204.23:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.204.23/47.101.204.23:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.204.23/47.101.204.23:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.204.23/47.101.204.23:2181, sessionid = 0x37a8fa62b70948d, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b70948d, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590383000,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3cc2931c
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7193666c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b70948d, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 2,4  replyHeader:: 2,8590383000,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@1f83db5b
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 8080 (auto-detected)
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 32768
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.linkCapacity: 16
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Close zookeeper connection 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Stopping rpc client
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Closing session: 0x37a8fa62b70948d
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - Closing client for session: 0x37a8fa62b70948d
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x3b2da18f to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:os.version=6.3
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.name=澡雪青
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.home=C:\Users\LXQ
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Client environment:user.dir=D:\coder\lixiaoqing
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 sessionTimeout=90000 watcher=org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient$$Lambda$5/2056402030@7e0fe73e
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server 47.101.204.23/47.101.204.23:2181. Will not attempt to authenticate using SASL (unknown error)
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to 47.101.204.23/47.101.204.23:2181, initiating session
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on 47.101.204.23/47.101.204.23:2181
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server 47.101.204.23/47.101.204.23:2181, sessionid = 0x37a8fa62b7094a5, negotiated timeout = 40000
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b7094a5, packet:: clientPath:/hbase/hbaseid serverPath:/hbase/hbaseid finished:false header:: 1,4  replyHeader:: 1,8590383236,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffffa464ffffffac20fffffffeffffff89742c50425546a2434326661376532302d366138622d343365392d396636372d623663383633336238343538,s{8590270937,8590270937,1627199321070,1627199321070,0,0,0,0,67,0,8590270937} 
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.level: simple
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector - -Dorg.apache.hbase.thirdparty.io.netty.leakDetection.targetRecords: 4
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - Platform: Windows
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - Java version: 8
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: C:\Users\LXQ\AppData\Local\Temp (java.io.tmpdir)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1873805312 bytes
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
DEBUG main org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@3cc2931c
DEBUG main org.apache.hbase.thirdparty.io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
DEBUG main org.apache.hadoop.hbase.util.ClassSize - Using Unsafe to estimate memory layout
DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7193666c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 16
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
DEBUG main org.apache.hbase.thirdparty.io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
DEBUG ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x3b2da18f-SendThread(47.101.204.23:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x37a8fa62b7094a5, packet:: clientPath:/hbase/meta-region-server serverPath:/hbase/meta-region-server finished:false header:: 2,4  replyHeader:: 2,8590383236,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff000146d61737465723a31363030305feffffffddffffffe2ffffffa422ffffffab1950425546a18ac6a696b656861646f6f70303510ffffff947d18fffffff3ffffff8cffffff8dffffffe5ffffffad2f100183,s{8590270976,8590349141,1627199326583,1627462136021,7,0,0,0,59,0,8590270976} 
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.AbstractByteBuf - -Dorg.apache.hbase.thirdparty.io.netty.buffer.bytebuf.checkAccessible: true
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetectorFactory - Loaded default ResourceLeakDetector: org.apache.hbase.thirdparty.io.netty.util.ResourceLeakDetector@1ed344aa
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.processId: 11560 (auto-detected)
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.NetUtil - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.channel.DefaultChannelId - -Dio.netty.machineId: a4:c3:f0:ff:fe:92:95:91 (auto-detected)
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 16
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 16
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 65536
DEBUG hconnection-0x397fbdb-metaLookup-shared--pool4-t1 org.apache.hbase.thirdparty.io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxCapacityPerThread: 32768
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.maxSharedCapacityFactor: 2
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.linkCapacity: 16
DEBUG Default-IPC-NioEventLoopGroup-1-1 org.apache.hbase.thirdparty.io.netty.util.Recycler - -Dio.netty.recycler.ratio: 8
DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
DEBUG main org.apache.hadoop.util.NativeCodeLoader - Loaded the native-hadoop library
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMapping - Using JniBasedUnixGroupsMapping for Group resolution
DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since startup], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Renewal failures since last successful login], valueName=Time)
DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
DEBUG main org.apache.hadoop.security.SecurityUtil - Setting hadoop.security.token.service.use_ip to true
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:NTUserPrincipal: ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - Using user: "NTUserPrincipal: ÔèѩÇà" with name ÔèѩÇà
DEBUG main org.apache.hadoop.security.UserGroupInformation - User entry: "ÔèѩÇà"
DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:ÔèѩÇà (auth:SIMPLE)
INFO main org.apache.hadoop.hbase.zookeeper.ReadOnlyZKClient - Connect 0x06b419da to 47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181 with session timeout=90000ms, retries 30, retry interval 1000ms, keepAlive=60000ms
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:host.name=DESKTOP-BVQVDII.mshome.net
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_45
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:java.home=D:\install\big_data\jdk\jdk1.8\jre
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=D:\install\big_data\jdk\jdk1.8\jre\lib\charsets.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\deploy.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\access-bridge-64.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\cldrdata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\dnsns.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jaccess.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\jfxrt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\localedata.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\nashorn.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunec.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunjce_provider.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunmscapi.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\sunpkcs11.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\ext\zipfs.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\javaws.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jce.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfr.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jfxswt.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\jsse.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\management-agent.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\plugin.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\resources.jar;D:\install\big_data\jdk\jdk1.8\jre\lib\rt.jar;D:\coder\lixiaoqing\target\classes;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-common\3.0.0\hadoop-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-annotations\3.0.0\hadoop-annotations-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\google\guava\guava\11.0.2\guava-11.0.2.jar;D:\install\big_data\maven\maven\repo\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;D:\install\big_data\maven\maven\repo\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar;D:\install\big_data\maven\maven\repo\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;D:\install\big_data\maven\maven\repo\commons-io\commons-io\2.4\commons-io-2.4.jar;D:\install\big_data\maven\maven\repo\commons-net\commons-net\3.1\commons-net-3.1.jar;D:\install\big_data\maven\maven\repo\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;D:\install\big_data\maven\maven\repo\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-server\9.3.19.v20170502\jetty-server-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-http\9.3.19.v20170502\jetty-http-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-io\9.3.19.v20170502\jetty-io-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util\9.3.19.v20170502\jetty-util-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-servlet\9.3.19.v20170502\jetty-servlet-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-security\9.3.19.v20170502\jetty-security-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-webapp\9.3.19.v20170502\jetty-webapp-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-xml\9.3.19.v20170502\jetty-xml-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-core\1.19\jersey-core-1.19.jar;D:\install\big_data\maven\maven\repo\javax\ws\rs\jsr311-api\1.1.1\jsr311-api-1.1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-servlet\1.19\jersey-servlet-1.19.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-json\1.19\jersey-json-1.19.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;D:\install\big_data\maven\maven\repo\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-core-asl\1.9.2\jackson-core-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-mapper-asl\1.9.2\jackson-mapper-asl-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-jaxrs\1.9.2\jackson-jaxrs-1.9.2.jar;D:\install\big_data\maven\maven\repo\org\codehaus\jackson\jackson-xc\1.9.2\jackson-xc-1.9.2.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-server\1.19\jersey-server-1.19.jar;D:\install\big_data\maven\maven\repo\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;D:\install\big_data\maven\maven\repo\log4j\log4j\1.2.17\log4j-1.2.17.jar;D:\install\big_data\maven\maven\repo\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;D:\install\big_data\maven\maven\repo\commons-beanutils\commons-beanutils\1.9.3\commons-beanutils-1.9.3.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-configuration2\2.1.1\commons-configuration2-2.1.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-lang3\3.4\commons-lang3-3.4.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-api\1.7.25\slf4j-api-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\slf4j\slf4j-log4j12\1.7.25\slf4j-log4j12-1.7.25.jar;D:\install\big_data\maven\maven\repo\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;D:\install\big_data\maven\maven\repo\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;D:\install\big_data\maven\maven\repo\org\xerial\snappy\snappy-java\1.0.5\snappy-java-1.0.5.jar;D:\install\big_data\maven\maven\repo\com\google\re2j\re2j\1.1\re2j-1.1.jar;D:\install\big_data\maven\maven\repo\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-auth\3.0.0\hadoop-auth-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\nimbusds\nimbus-jose-jwt\4.41.1\nimbus-jose-jwt-4.41.1.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\jcip\jcip-annotations\1.0-1\jcip-annotations-1.0-1.jar;D:\install\big_data\maven\maven\repo\net\minidev\json-smart\2.3\json-smart-2.3.jar;D:\install\big_data\maven\maven\repo\net\minidev\accessors-smart\1.2\accessors-smart-1.2.jar;D:\install\big_data\maven\maven\repo\org\ow2\asm\asm\5.0.4\asm-5.0.4.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-framework\2.12.0\curator-framework-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\jcraft\jsch\0.1.54\jsch-0.1.54.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-client\2.12.0\curator-client-2.12.0.jar;D:\install\big_data\maven\maven\repo\org\apache\curator\curator-recipes\2.12.0\curator-recipes-2.12.0.jar;D:\install\big_data\maven\maven\repo\com\google\code\findbugs\jsr305\3.0.0\jsr305-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\htrace\htrace-core4\4.1.0-incubating\htrace-core4-4.1.0-incubating.jar;D:\install\big_data\maven\maven\repo\org\apache\zookeeper\zookeeper\3.4.9\zookeeper-3.4.9.jar;D:\install\big_data\maven\maven\repo\jline\jline\0.9.94\jline-0.9.94.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;D:\install\big_data\maven\maven\repo\org\tukaani\xz\1.0\xz-1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-simplekdc\1.0.1\kerb-simplekdc-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-client\1.0.1\kerb-client-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-config\1.0.1\kerby-config-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-core\1.0.1\kerb-core-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-pkix\1.0.1\kerby-pkix-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-asn1\1.0.1\kerby-asn1-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-util\1.0.1\kerby-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-common\1.0.1\kerb-common-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-crypto\1.0.1\kerb-crypto-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-util\1.0.1\kerb-util-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\token-provider\1.0.1\token-provider-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-admin\1.0.1\kerb-admin-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-server\1.0.1\kerb-server-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerb-identity\1.0.1\kerb-identity-1.0.1.jar;D:\install\big_data\maven\maven\repo\org\apache\kerby\kerby-xdr\1.0.1\kerby-xdr-1.0.1.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-databind\2.7.8\jackson-databind-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-annotations\2.7.0\jackson-annotations-2.7.0.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\core\jackson-core\2.7.8\jackson-core-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\codehaus\woodstox\stax2-api\3.1.4\stax2-api-3.1.4.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\woodstox\woodstox-core\5.0.3\woodstox-core-5.0.3.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs\3.0.0\hadoop-hdfs-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\eclipse\jetty\jetty-util-ajax\9.3.19.v20170502\jetty-util-ajax-9.3.19.v20170502.jar;D:\install\big_data\maven\maven\repo\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;D:\install\big_data\maven\maven\repo\io\netty\netty\3.10.5.Final\netty-3.10.5.Final.jar;D:\install\big_data\maven\maven\repo\io\netty\netty-all\4.0.23.Final\netty-all-4.0.23.Final.jar;D:\install\big_data\maven\maven\repo\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-core\3.0.0\hadoop-mapreduce-client-core-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-client\3.0.0\hadoop-yarn-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-api\3.0.0\hadoop-yarn-api-3.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-yarn-common\3.0.0\hadoop-yarn-common-3.0.0.jar;D:\install\big_data\maven\maven\repo\javax\xml\bind\jaxb-api\2.2.11\jaxb-api-2.2.11.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\jersey-client\1.19\jersey-client-1.19.jar;D:\install\big_data\maven\maven\repo\com\google\inject\guice\4.0\guice-4.0.jar;D:\install\big_data\maven\maven\repo\javax\inject\javax.inject\1\javax.inject-1.jar;D:\install\big_data\maven\maven\repo\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;D:\install\big_data\maven\maven\repo\com\sun\jersey\contribs\jersey-guice\1.19\jersey-guice-1.19.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\module\jackson-module-jaxb-annotations\2.7.8\jackson-module-jaxb-annotations-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-json-provider\2.7.8\jackson-jaxrs-json-provider-2.7.8.jar;D:\install\big_data\maven\maven\repo\com\fasterxml\jackson\jaxrs\jackson-jaxrs-base\2.7.8\jackson-jaxrs-base-2.7.8.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-hdfs-client\3.0.0\hadoop-hdfs-client-3.0.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okhttp\okhttp\2.4.0\okhttp-2.4.0.jar;D:\install\big_data\maven\maven\repo\com\squareup\okio\okio\1.4.0\okio-1.4.0.jar;D:\install\big_data\maven\maven\repo\com\google\inject\extensions\guice-servlet\4.0\guice-servlet-4.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hadoop\hadoop-mapreduce-client-common\3.0.0\hadoop-mapreduce-client-common-3.0.0.jar;D:\install\big_data\jdk\jdk1.8.2\lib\tools.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-client\2.1.0\hbase-client-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-protobuf\2.1.0\hbase-shaded-protobuf-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-common\2.1.0\hbase-common-2.1.0.jar;D:\install\big_data\maven\maven\repo\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop-compat\2.1.0\hbase-hadoop-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics-api\2.1.0\hbase-metrics-api-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-hadoop2-compat\2.1.0\hbase-hadoop2-compat-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-metrics\2.1.0\hbase-metrics-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol-shaded\2.1.0\hbase-protocol-shaded-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\hbase-protocol\2.1.0\hbase-protocol-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-miscellaneous\2.1.0\hbase-shaded-miscellaneous-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\apache\hbase\thirdparty\hbase-shaded-netty\2.1.0\hbase-shaded-netty-2.1.0.jar;D:\install\big_data\maven\maven\repo\org\jruby\jcodings\jcodings\1.0.18\jcodings-1.0.18.jar;D:\install\big_data\maven\maven\repo\org\jruby\joni\joni\2.1.11\joni-2.1.11.jar;D:\install\big_data\maven\maven\repo\io\dropwizard\metrics\metrics-core\3.2.1\metrics-core-3.2.1.jar;D:\install\big_data\maven\maven\repo\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;D:\install\big_data\maven\maven\repo\org\apache\yetus\audience-annotations\0.5.0\audience-annotations-0.5.0.jar;D:\install\big_data\idea\IntelliJ IDEA 2019.2\lib\idea_rt.jar
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=D:\install\big_data\jdk\jdk1.8\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin;D:\install\big_data\idea\IntelliJ IDEA 2019.2\jbr\\bin\server;D:\install\big_data\Anaconda\Anaconda3;D:\install\big_data\Anaconda\Anaconda3\Library\mingw-w64\bin;D:\install\big_data\Anaconda\Anaconda3\Library\usr\bin;D:\install\big_data\Anaconda\Anaconda3\Library\bin;D:\install\big_data\Anaconda\Anaconda3\Scripts;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;D:\install\big_data\xshell\xsehll\;D:\install\big_data\xshell\xftp\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;D:\install\big_data\SVN\bin;D:\install\big_data\Git\Git\bin;D:\install\big_data\Mysql\mysql-5.7.27-winx64\bin;C:\Program Files\Microsoft VS Code\bin;D:\install\big_data\jdk\jdk1.8.2\bin;D:\install\big_data\jdk\jdk1.8.2\jre\bin;D:\install\big_data\maven\apache-maven-3.5.2\bin;D:\install\tool\NodeJS\12\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;D:\install\tool\UE;D:\install\tool\rsync\bin;D:\install\tool\VPN\OpenVPN\bin;D:\install\big_data\hadoop\hadoop-3.3.0\bin;C:\Users\LXQ\AppData\Local\Microsoft\WindowsApps;C:\Users\澡雪青\AppData\Roaming\npm;;D:\install\tool\VScode\Microsoft VS Code\bin;.
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=C:\Users\LXQ\AppData\Local\Temp\
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:os.name=Windows 8.1
INFO ReadOnlyZKClient-47.101.204.23:2181,47.101.216.12:2181,47.101.206.249:2181@0x06b419da org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
